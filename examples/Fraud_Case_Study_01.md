## ðŸ“„ `examples/Fraud_Case_Study_01.md`
```markdown
# Fraud Case Study 01 â€“ AI Voice Scam

## Scenario
- Scammer uses AI-generated synthetic voice to impersonate a family member.
- Victim receives urgent call requesting money transfer.

---

## Risk Factors
- Free, unverified access to voice-cloning tools.
- Lack of traceability.
- No embedded watermark or audit logs.

---

## Policy Countermeasures
- Restrict synthetic voice tools to paid + verified accounts.
- Embed invisible audio watermarks.
- Alert system for mass-generation patterns.

